#!/usr/bin/env python3
"""
Objectives Manager
-----------------
This module manages the execution of objectives generated by the 
Narrative Discovery Matrix.
"""

import os
import json
import time
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
import importlib.util
import sys

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'logs', 'objectives.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('objectives_manager')

# Import the narrative matrix
from core.narrative_matrix import NarrativeMatrix

class ObjectivesManager:
    """
    Manages the execution of objectives generated by the Narrative Matrix.
    Integrates with existing crawler and research tools.
    """
    
    def __init__(self):
        """Initialize the objectives manager."""
        # Paths
        self.base_path = os.path.dirname(os.path.dirname(__file__))
        self.current_objective_path = os.path.join(
            self.base_path, 'results', 'current_objective.txt'
        )
        
        # Initialize the narrative matrix
        self.matrix = NarrativeMatrix()
        
        # Initialize variables to track execution state
        self.current_objective = None
        self.execution_start_time = None
        self.last_discovery_time = None
        self.discoveries_count = 0
        
        # Check for and attempt to load crawler module
        self.crawler_available = False
        self.crawler = self._load_crawler()
        
        # Check for and attempt to load LLM integration
        self.llm_available = False
        self.llm = self._load_llm_integration()
    
    def _load_crawler(self):
        """
        Attempt to load the existing crawler module.
        Returns None if not available.
        """
        try:
            # Try different possible locations for the crawler
            crawler_paths = [
                os.path.join(self.base_path, 'crawler.py'),
                os.path.join(self.base_path, 'crawler', 'crawler.py'),
                os.path.join(self.base_path, '..', 'crawler.py')
            ]
            
            for path in crawler_paths:
                if os.path.exists(path):
                    logger.info(f"Found crawler at {path}")
                    
                    # Load the module
                    module_name = os.path.basename(path).replace('.py', '')
                    spec = importlib.util.spec_from_file_location(module_name, path)
                    crawler_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(crawler_module)
                    
                    self.crawler_available = True
                    logger.info("Successfully loaded crawler module")
                    return crawler_module
            
            logger.warning("Crawler module not found. Running in limited mode.")
            return None
        except Exception as e:
            logger.error(f"Error loading crawler module: {e}")
            return None
    
    def _load_llm_integration(self):
        """
        Attempt to load the existing LLM integration module.
        Returns None if not available.
        """
        try:
            # Try different possible locations for the LLM integration
            llm_paths = [
                os.path.join(self.base_path, 'llm_integration.py'),
                os.path.join(self.base_path, 'llm', 'integration.py'),
                os.path.join(self.base_path, '..', 'llm_integration.py')
            ]
            
            for path in llm_paths:
                if os.path.exists(path):
                    logger.info(f"Found LLM integration at {path}")
                    
                    # Load the module
                    module_name = os.path.basename(path).replace('.py', '')
                    spec = importlib.util.spec_from_file_location(module_name, path)
                    llm_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(llm_module)
                    
                    self.llm_available = True
                    logger.info("Successfully loaded LLM integration module")
                    return llm_module
            
            logger.warning("LLM integration module not found. Running in limited mode.")
            return None
        except Exception as e:
            logger.error(f"Error loading LLM integration module: {e}")
            return None
    
    def load_current_objective(self) -> Optional[str]:
        """
        Load the current objective from file or generate a new one if none exists.
        
        Returns:
            The current objective text, or None if generation failed
        """
        # Check if there's a current objective file
        if os.path.exists(self.current_objective_path):
            with open(self.current_objective_path, 'r') as f:
                objective_text = f.read().strip()
                
            logger.info(f"Loaded existing objective: {objective_text}")
            self.current_objective = objective_text
            return objective_text
        
        # No current objective, generate a new one
        try:
            objective_text = self.matrix.generate_objective()
            self.current_objective = objective_text
            logger.info(f"Generated new objective: {objective_text}")
            return objective_text
        except Exception as e:
            logger.error(f"Failed to generate objective: {e}")
            return None
    
    def execute_research(self) -> List[Dict[str, Any]]:
        """
        Execute research for the current objective using available tools.
        
        Returns:
            List of discovery dictionaries
        """
        if not self.current_objective:
            logger.error("No current objective to research")
            return []
        
        # Initialize timing information for this execution
        self.execution_start_time = datetime.now()
        
        # Parse the objective to extract artifact_type and entity
        # This is a simplified parsing, assuming the format:
        # "Find {artifact_type} around {entity}" or similar
        words = self.current_objective.split()
        # Simple heuristic: artifact_type is usually after "Find" and entity is after "around"
        artifact_type = None
        entity = None
        
        for i, word in enumerate(words):
            if word.lower() in ["find", "discover"] and i+1 < len(words):
                artifact_type = words[i+1]
            if word.lower() in ["around", "related", "associated", "connected"] and i+1 < len(words):
                entity = " ".join(words[i+1:])
                # Remove any trailing punctuation
                entity = entity.rstrip(".,:;")
        
        logger.info(f"Parsed objective - Artifact type: {artifact_type}, Entity: {entity}")
        
        discoveries = []
        
        # If we have a crawler, use it to research
        if self.crawler_available and hasattr(self.crawler, 'search'):
            try:
                logger.info(f"Starting crawler research for: {self.current_objective}")
                
                # The exact API of the crawler is assumed here and may need adjustment
                crawler_results = self.crawler.search(
                    keywords=[artifact_type, entity],
                    max_results=10,
                    depth=2
                )
                
                for result in crawler_results:
                    discovery = {
                        "source": "crawler",
                        "url": result.get("url", ""),
                        "title": result.get("title", ""),
                        "content": result.get("content", ""),
                        "timestamp": datetime.now().isoformat()
                    }
                    discoveries.append(discovery)
                    
                    # Record the discovery in the matrix
                    self.matrix.record_discovery(discovery)
                    self.last_discovery_time = datetime.now()
                    self.discoveries_count += 1
                
                logger.info(f"Crawler found {len(crawler_results)} results")
            except Exception as e:
                logger.error(f"Error during crawler research: {e}")
        
        # If we have LLM integration, use it to analyze and enhance discoveries
        if self.llm_available and discoveries and hasattr(self.llm, 'analyze'):
            try:
                logger.info("Using LLM to analyze discoveries")
                
                # The exact API of the LLM integration is assumed here
                enhanced_discoveries = []
                
                for discovery in discoveries:
                    # Analyze the discovery content
                    analysis = self.llm.analyze(
                        text=discovery["content"],
                        context=f"Looking for {artifact_type} related to {entity}"
                    )
                    
                    # Extract entities and determine if this is narrative-worthy
                    entities = analysis.get("entities", [])
                    is_narrative = analysis.get("narrative_score", 0) > 0.7
                    
                    # Enhance the discovery with analysis
                    enhanced_discovery = {
                        **discovery,
                        "entities": entities,
                        "sentiment": analysis.get("sentiment", "neutral"),
                        "relevance": analysis.get("relevance_score", 0.5),
                        "analysis_summary": analysis.get("summary", "")
                    }
                    
                    enhanced_discoveries.append(enhanced_discovery)
                    
                    # Record the enhanced discovery
                    self.matrix.record_discovery(enhanced_discovery, narrative_worthy=is_narrative)
                    self.last_discovery_time = datetime.now()
                
                logger.info(f"LLM enhanced {len(enhanced_discoveries)} discoveries")
                return enhanced_discoveries
            except Exception as e:
                logger.error(f"Error during LLM analysis: {e}")
        
        return discoveries
    
    def is_objective_exhausted(self) -> bool:
        """
        Check if the current objective is exhausted or at a dead end.
        
        Returns:
            Boolean indicating if we should move to the next objective
        """
        # If no objective, we need a new one
        if not self.current_objective:
            return True
        
        # Check if the matrix thinks this is a dead end
        if self.matrix.is_dead_end():
            logger.info("Matrix determined the objective is at a dead end")
            return True
        
        # Check our own criteria - no discoveries after trying
        if (self.execution_start_time and 
            self.discoveries_count == 0 and
            (datetime.now() - self.execution_start_time).total_seconds() > 600):  # 10 minutes
            logger.info("No discoveries after 10 minutes of execution")
            return True
        
        return False
    
    def generate_related_objectives(self) -> List[str]:
        """
        Generate related objectives based on discoveries.
        
        Returns:
            List of related objective strings
        """
        followups = self.matrix.generate_followup_objectives()
        if followups:
            logger.info(f"Generated {len(followups)} related objectives")
        else:
            logger.info("No related objectives generated")
        
        return followups
    
    def move_to_next_objective(self) -> Optional[str]:
        """
        Move to the next objective in the matrix.
        
        Returns:
            The new objective text, or None if generation failed
        """
        if self.current_objective:
            # Mark the current objective as complete
            self.matrix.mark_objective_complete()
            logger.info(f"Marked objective as complete: {self.current_objective}")
        
        # Reset execution state
        self.execution_start_time = None
        self.last_discovery_time = None
        self.discoveries_count = 0
        
        # Generate and load a new objective
        return self.load_current_objective()
    
    def run_autonomous_cycle(self, max_cycles: int = 5, cycle_delay: int = 60) -> None:
        """
        Run an autonomous cycle of objective generation, research, and analysis.
        
        Args:
            max_cycles: Maximum number of objective cycles to run
            cycle_delay: Delay in seconds between cycles
        """
        logger.info(f"Starting autonomous cycle with max_cycles={max_cycles}")
        
        for cycle in range(max_cycles):
            logger.info(f"Starting cycle {cycle+1}/{max_cycles}")
            
            # Load or generate an objective
            objective = self.load_current_objective()
            if not objective:
                logger.error("Failed to load or generate an objective. Stopping cycle.")
                break
            
            logger.info(f"Working on objective: {objective}")
            
            # Execute research for this objective
            discoveries = self.execute_research()
            logger.info(f"Found {len(discoveries)} discoveries for this objective")
            
            # Check if we should move to the next objective
            if self.is_objective_exhausted():
                logger.info("Objective is exhausted, generating related objectives")
                
                # Generate related objectives first
                related_objectives = self.generate_related_objectives()
                for related in related_objectives:
                    logger.info(f"Related objective: {related}")
                
                # Move to the next objective
                next_objective = self.move_to_next_objective()
                logger.info(f"Moved to next objective: {next_objective}")
            
            # Wait before the next cycle
            if cycle < max_cycles - 1:
                logger.info(f"Waiting {cycle_delay} seconds before next cycle")
                time.sleep(cycle_delay)
        
        logger.info("Completed autonomous cycle")

if __name__ == "__main__":
    # Create logs directory if it doesn't exist
    os.makedirs(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'logs'), exist_ok=True)
    
    # Initialize and run the objectives manager
    manager = ObjectivesManager()
    
    # Display system status
    print("Narrative Discovery Matrix System")
    print("=================================")
    print(f"Crawler available: {manager.crawler_available}")
    print(f"LLM integration available: {manager.llm_available}")
    
    # Load current objective or generate a new one
    objective = manager.load_current_objective()
    print(f"Current objective: {objective}")
    
    # Run a short autonomous cycle as a test
    manager.run_autonomous_cycle(max_cycles=2, cycle_delay=10)
    
    print("System is ready for autonomous operation")